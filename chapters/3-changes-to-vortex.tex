\chapter{Changes to Vortex} \label{chap:changes}

In this chapter I will first give an overview of the \Gls{vortex} architecture and pipeline. Then I will describe the identified bottlenecks and the proposed changes to improve scheduling and frontend throughput. 

\section{Vortex Architecture}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/vortex-pipeline3.png}
    \caption{\Gls{vortex} \Gls{riscv} 5-stage pipeline of a \acrfull{sm}}
    \label{fig:vortex_microarchitecture}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/vortex-cluster-color.png}
    \caption[Clustering of \acrshortpl{sm} in \Gls{vortex}.]{Example of \acrshortpl{sm} clustering in \Gls{vortex} using 2 clusters and 4 \acrshortpl{sm} per cluster. The L2 and L3 caches are optional, if they are not included, memory arbiters are used.}
    \label{fig:clustering}
\end{figure}

Other than what is written in the \Gls{vortex} paper~\cite{Aurud_Project}, \Gls{vortex} is mostly undocumented. Most of my understanding of \Gls{vortex}' architecture and software stack is thus derived from reading the source code. The \Gls{vortex} microarchitecture is illustrated in Figure~\ref{fig:vortex_microarchitecture}. Each \acrshort{sm} is a 5-stage pipeline containing a \textit{fetch}, \textit{decode}, \textit{issue}, \textit{execute} and \textit{commit} stage. The \acrshortpl{sm} of \Gls{vortex} all have their own L1 and instruction caches. There are also options for \Gls{vortex} to include L2 and L3 caches, which are shared among \acrshortpl{sm}, as shown in Figure~\ref{fig:clustering}. If the L2 or L3 caches are not included, they are replaced by memory arbiters. \Gls{vortex}' pipeline is elastic~\cite{elastic_pipeline}, i.e. it is using \textit{ready} and \textit{valid} signals to communicate between the modules and pipeline stages. This makes it easier to add new or configure existing components, as the modules can be more flexible in the number of cycles they use.

\subsection{Vortex ISA}

Vortex extends the \gls{riscv}~\acrshort{isa}~\cite{riscv-isa} with six new instructions:
\begin{itemize}
    \item \textbf{wspawn}: Controlling warps by activating a number of warps at a specified \acrshort{pc}.
    \item \textbf{tmc}: Controlling threads by activating or deactivating threads within a warp. 
    \item \textbf{split \& join}: Handling control divergence. \textit{Split} pushes information about the current state of the thread-mask and branching to the \acrfull{ipdom} stack, and \textit{join} pops the information off the stack to reconverge the branches.
    \item \textbf{bar}: Synchronizing warps, both intra-core and inter-core, using barriers. The barrier is released when the expected number of warps has reached it.  
    \item \textbf{tex}: Texture lookup with a variety of configurable features, such as mipmapping. 
\end{itemize}

\subsection{Pipeline} \label{sec:vortex_pipeline}
Following is a description of the five pipeline stages of \Gls{vortex}' \acrshortpl{sm}.

\vspace{1mm}\noindent
\textbf{The fetch stage} is responsible for scheduling warps, keeping track of branches, divergence and barriers. The warp scheduler keeps track of the active, stalled and blocked warps using bitmasks. The baseline version of \Gls{vortex} use a \textit{find-first} scheduler, which prioritizes scheduling the ready warp with the lowest warp ID. This will be further explained in Section \ref{sec:warp_issue_scheduler}. Upon scheduling a warp, the warp scheduler sends an instruction-fetch-request to the icache-stage in decode. In the baseline version of \Gls{vortex}, only one warp from each \acrshort{tb} can be fetched concurrently. Since vortex does not support branch prediction, the warp has to be stalled until it is known that it cannot change control-flow. The first point in the pipeline this can be known is after decoding the instruction. If the instruction is not a branch, barrier or thread mask control, the warp will no longer be marked as stalled in the warp-scheduler. Otherwise, the warp continues to be stalled until the instruction completes execution.

\noindent
\textbf{The decode stage} contains a decoder and the icache-stage. The icache-stage is illustrated in Figure \ref{fig:baseline_icache_stage}. The purpose of the icache-stage is to enable fetching instructions from multiple \acrshortpl{tb} concurrently. The icache-stage use dual-port RAM with one write address per \acrshort{tb} in the \acrshort{sm}, to store information about the requested instruction. The request is simultaneously sent to the icache. Upon receiving a response from the icache, the corresponding request information is read from RAM and combined with the instruction data, to create the response. The response is then sent to the decoder, which decodes the instruction using sequential logic. The decoder also informs the fetch stage whether or not the instruction can change control flow. After decoding, the instruction is sent to the instruction buffer in the issue stage.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/Baseline Icache-stage.png}
    \caption{Illustration of \Gls{vortex}' icache-stage.}
    \label{fig:baseline_icache_stage}
\end{figure}

\vspace{1mm}\noindent
\textbf{The issue stage}, shown in Figure \ref{fig:baseline_issue_stage}, is responsible for issuing the warps to the functional units. To handle data dependencies, \Gls{vortex} utilize scoreboarding. The warps are issued in order, but is committed in the order in which the execution is completed. When instructions are decoded, they are transferred to the instruction buffer (ibuffer). The ibuffer contains a queue for each \acrshort{tb} in the \acrshort{sm}. The issue stage has an instruction scheduler which schedules warps from the front of one of the queues in the ibuffer and dispatches it to the corresponding functional unit in the execution stage.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Baseline Issue Stage.png}
    \caption{Illustration of \Gls{vortex}' issue stage}
    \label{fig:baseline_issue_stage}
\end{figure}

The instruction scheduler used in the baseline version of \Gls{vortex} is a round-robin scheduler. For a warp to be issued, the source and destination registers must be available in the scoreboard and the corresponding functional unit must be available in dispatch. The instruction scheduler attempts to issue one of the available warps in the ibuffer in a round-robin order. The issue stage can however in each cycle only check for one warp whether it is ready or not. Thus if the selected warp cannot be issued, no warp is issued in that cycle. I cover this problem in greater detail and propose an improvement in Section \ref{sec:ready_scheduling}. 
% \noindent
% Observe that if the queue in the Ibuffer, corresponding to the warp id of the warp in decode is full, the front-end will stall. Thus if one warp is stalling, other warps can be blocked from scheduling.

\vspace{1mm}\noindent
\textbf{The execute stage} consists of five functional units. The \textit{\acrlong{alu}} (\acrshort{alu}) performs logic and integer arithmetic operations in addition to handling branches. The \textit{\acrlong{lsu}} (\acrshort{lsu}) performs memory loads and stores. The \textit{\acrlong{csr}} (\acrshort{csr}) holds a number of status registers which can be read and written to using csr instructions. Some of these influence how graphics are rendered, by controlling sampling modes, texture addresses etc. The \acrshort{csr} also track a number of performance metrics, such as the number of commited instructions and the number cycles used. The \textit{\acrlong{gpu}} (\acrshort{gpu}) performs texture sampling as well as sending control signals to the fetch stage in regards to warp spawning, divergence, barriers and thread masks. Lastly the \textit{\acrlong{fpu}} (\acrshort{fpu}) performs floating point operations.

\vspace{1mm}\noindent
\textbf{The commit stage} is the last stage in the pipeline. When instructions are finished in the execute stage, the results are written back to the \acrfull{gpr}. The registers reserverd by the instruction is also released in the scoreboard.

\subsection{Workload Distribution}

\Gls{vortex}' workload distribution and \acrshort{tb} scheduling is performed statically. Upon starting the execution of a kernel, each \acrshort{sm} calculates the total number of active \acrshortpl{sm} required. The number of \acrshortpl{sm} required is calculated as:
\begin{equation}
    \#SMs_{active} = \text{min}(\frac{\#TBs}{\#WarpsPerSM \times \#ThreadsPerSM}, \#SMs)
\end{equation}
\noindent
The \acrshortpl{tb} are then divided evenly among the active \acrshortpl{sm}. If there are more \acrshortpl{tb} than the total number slots available in \Gls{vortex}, the last \acrshort{sm} is allocated all of the remaining \acrshortpl{tb}. This can result in very inefficient workload distribution, and the programs running on the \acrshort{gpu} have to be adjusted before compilation to best fit the architecture. Static workload distribution also have another weakness. If for some reason the \acrshortpl{sm} require different amount of time to complete their workload, the \acrshortpl{sm} which finish early, end up idling while waiting for the other \acrshortpl{sm} to complete their workloads. The difference in execution time, can stem from multiple causes. The memory system could prioritize requests from certain \acrshortpl{sm}, or the workloads could differ, for example in terms of divergence. This results in unused computational power and reduces throughput of the \acrshort{gpu}. While I do not propose or implement any solutions to this problem in this thesis, it is relevant for understanding the results and evaluation in Chapter~\ref{chap:results}.

\section{Scheduling Algorithms}

\subsection{Ready Scheduling} \label{sec:ready_scheduling}

The baseline issue scheduler in \Gls{vortex}, described in Section \ref{sec:vortex_pipeline}, attempts to issue an available warp before checking if it is ready. As the scheduler is round-robin, this can potentially be detrimental to the performance. If 1 out of $N$ warps are ready while the $N-1$ other warps are stalling, the scheduler could potentially waste $N$ cycles before issuing the warp. An example of this is shown in Figure~\ref{fig:unready_lrr}. While this is the most extreme case, cases of similar severity are likely to occur. Using a \textit{ready scheduler}, which checks for ready warps before scheduling, will guarantee that it only takes 1 cycle to schedule a warp if at least one is ready.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/old_lrr_scheduler.png}
    \caption{Illustrating the inefficiency of the baseline issue scheduler. The \textit{unready} \acrshort{lrr} scheduler wastes cycles by attempting to issue stalled warps from the ibuffer}
    \label{fig:unready_lrr}
\end{figure}

Figure \ref{fig:new_issue_stage} illustrates the new issue stage implemented by me. It performs the ready check for all warps before the instruction scheduler selects the warp to issue. Each warp checks if it is ready by: \textcircled{\small{1}} Check in dispatch if the corresponding \acrshortpl{fu} is available. \textcircled{\small{2}} Check in scoreboard if the required operands are available. \textcircled{\small{3}} Use bitwise AND to create a bitmask of ready warps. \textcircled{\small{4}} Create a bitmask of valid warps which can be issued, by finding the bitwise AND of the ready warps and the warps available in the ibuffer. The instruction scheduler can then select a ready warp from this bitmask. \textcircled{\small{5}} The selected warp ID is sent back to the ibuffers, dispatch, scoreboard to update their values. These changes result in a ready \acrfull{lrr} scheduler as described in Section~\ref{sec:warp_scheduling}.

The implementation of the new issue stage does not require much additional hardware. All the information is already available in scoreboard and dispatch, thus it mainly requires selectors for reading the correct registers. The scheduler does not need to be changed, as it continues to selects a warp from the bitmask. 

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/New Issue Stage.png}
    \caption[Illustration of the new issue stage.]{Illustration of the new issue stage allowing the instruction scheduler to check for ready warps before selecting which warp to issue.}
    \label{fig:new_issue_stage}
\end{figure}


\subsection{Greedy then Oldest}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/gto_numbers.png}
    \caption{Implementation of \acrfull{gto}.}
    \label{fig:gto_impl}
\end{figure}

After implementing ready scheduling, the possibility of implementing other scheduling algorithms become available.\Acrfull{gto} is a common and easy to understand algorithm with a potential to give improved performance over \acrfull{lrr}. I was unable to find implementation details of existing \acrshort{gto} schedulers, thus I had to implement my own. Figure~\ref{fig:gto_impl} illustrates my implementation of \acrshort{gto}. \textcircled{\small{1}} Is the set of ready warps in the form of a bitmask. \textcircled{\small{2}} Contains the ages of the warps, i.e the number of valid schedules which occurred, while the warp was ready. The age is calculated as described by Equation \ref{eq:age}. Issuing a warp might cause structural stalls for the other warps. Thus an alternative would be to use the warps' presence in the instruction buffer as a condition for incrementing the age, rather than it being ready. \textcircled{\small{3}} Use combinatorial logic to find the oldest ready warp using the ready mask and the age of each warp. \textcircled{\small{4}} Is the warp ID of the previously scheduled warp. If the previously scheduled warp ID is still ready, the greedy selector \textcircled{\small{5}} continues to select the warp ID, otherwise it selects the oldest ready warp.

% By only incrementing the age upon a schedule, the age registers does not require many bits to track the age of the warps. In my case, I found that  than if the age was incremented every cycle.

\begin{equation} \label{eq:age}
    \text{age}_i = 
    \begin{dcases}
            \text{age}_i, & \text{if } \text{valid} = 0 \text{ or ready}_i = 0  \\
            0, & \text{if } \text{valid = 1 and Scheduled WID = } i \\
            \text{age}_i + 1, & \text{otherwise}
    \end{dcases}
\end{equation}

\subsection{Matching Warp and Issue Schedulers} \label{sec:warp_issue_scheduler}

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/find-first-scheduling-2.png}
    \caption[Demonstration of \Gls{vortex}' find-first warp scheduler.]{Demonstration of\Gls{vortex}' \textit{find-first} warp scheduling algorithm. When the length of the stalls are shorter than $\text{\#Warps} - 1$ cycles, the low priority warps are scheduled substantially less than the high priority warps.}
    \label{fig:find_first_scheduling}
\end{figure}

As explained in Section \ref{sec:vortex_pipeline}, \Gls{vortex} has a \textit{warp scheduler} in the fetch stage. The algorithm currently used by this scheduler is \textit{find-first}, which prioritizes warps based on warp ID. Figure~\ref{fig:find_first_scheduling} illustrates how this algorithm can end up scheduling low-priority warps substantially less than high-priority warps. This can make some warps finishing long before others, resulting in idle cycles. This does not happen for the baseline version of \Gls{vortex}, as there are too many frontend stalls. However as I am going to improve the frontend, it is likely better to use a more traditional algorithm.

The interaction between the issue scheduler and the warp scheduler is likely to be important for the algorithms to achieve their goals. For example, if the warp scheduler fetches warps in \acrshort{lrr} order, a \acrshort{gto} issue scheduler will not have enough warps from the same \acrshort{tb} to see the effects of greedy scheduling. It is thus desirable to use scheduling algorithms for the warp scheduler which supports the goals of the issue scheduler. To achieve this I implement the same \acrshort{lrr} and \acrshort{gto} algorithms in the warp scheduler.

Implementing the algorithms in the warp scheduler is quite simple as the scheduler modules can be reused. Instead of using the bitmask of warps which are ready to issue as input, the bitmask of ready warps in fetch can be used for the warp scheduler. An issue which arise when implementing \acrshort{gto} in the warp scheduler is that \acrshort{gto} wants to fetch warps from the same \acrshort{tb} multiple cycles in a row. As explained in Section~\ref{sec:vortex_pipeline}, the warps are stalled after being scheduled to avoid potential control flow hazards. Thus a \acrshort{gto} warp scheduler will not have the intended behaviour when integrated into the existing pipeline. Section~\ref{sec:no_stall_scheduling} describes changes to the frontend which solve this issue.

\section{Frontend}

In my project thesis~\cite{Aurud_Project}, I found that \Gls{vortex}' frontend was unable to fetch enough instructions to the issue stage, impeding its ability to hide stalls. This section describes a set of changes done to improve the throughput of the frontend.

\subsection{No Stall Scheduling} \label{sec:no_stall_scheduling}

The root of the frontend problem is that \acrshortpl{tb} are stalled whenever their warps are scheduled. Most of the instructions does however not require stalling and are un-stalled after being decoded. As the default configuration of \Gls{vortex} has 4 \acrshortpl{tb} per \acrshort{sm}, it is unable to hide the latency of the instruction fetch. The high number of stalls thus reduce the throughput of the frontend. To avoid this, I propose \textit{\acrlong{nss}} (\acrshort{nss}), allowing the frontend to schedule warps without stalling, and instead flush the frontend if stalling is required. To further improve the efficiency of \acrshort{nss}, I propose \textit{stall-prediction} to reduce the number of flushed instructions, and make the frontend stall only when required.

\begin{figure}
    \centering
    \makebox[\textwidth][c]{\includegraphics[width=\textwidth]{figures/new-icache-stage.png}}
    \caption[Illustration of the improved icache-stage.]{Improved icache-stage allowing for multiple concurrent instruction fetch requests from each \acrshort{tb}}
    \label{fig:new_icache_stage}
\end{figure}

To implement \acrshort{nss}, two mechanisms are required. 1. The icache-stage needs to handle multiple concurrent instruction fetches from the same \acrshort{tb}. The responses to these requests have to be reordered, as the icache is non-blocking. 2. Flushing the instructions in case a stall is required. Figure \ref{fig:new_icache_stage} illustrates my design of the improved icache-stage. Instead of using dual-port RAM, which allows only one concurrent fetch request for each \acrshort{tb}, the new design use an insert queue, allowing for up to 8 concurrent instruction fetches per \acrshort{tb}. It is possible to implement an even larger queue, but I found that the number of in-flight requests per \acrshort{tb} rearly exceeded 8. The insert queue has two ports to writing data to. \textcircled{\small{1}} First the fetch request is pushed into the queue and sent to the icache. By using a queue, the order of the requests is maintained. \textcircled{\small{2}} Secondly, as the response is returned, the instruction data is inserted into the queue. The \acrshort{uuid} of the request and response is used to match the data with the request. When the first element in the queue is ready, i.e \textcircled{\small{3}} it contains both a valid request and the instruction data, it becomes available for \textcircled{\small{4}} the scheduler to forward it to decode. 

A scheduler is required, as it is possible for multiple queues to have ready elements at the same time. This is because the response data can be reordered, or the ibuffer can be full, causing back pressure. I elected to use \acrshort{gto} for the icache-stage scheduler as it is likely to conform with both an \acrshort{lrr} and \acrshort{gto} issue scheduler. I do however believe that the choice of algorithm will not impact the performance. Some preliminary testing also support this belief.

To not stall every time a fetch-request is sent, the warp scheduler have to predict if the instruction requires stalling or not. \acrshort{nss} initially predicts instructions never require stalling. This scheme has low overhead, as the scheduling continues as if nothing changed. Upon decoding an instruction it might require the frontend to stall or the thread mask to change. When this happens, \textcircled{\small{5}} all requests from the same \acrshort{tb} are flushed. This is done in the insert queue by setting the valid bit of each entry low. While the requests are flushed from the insert queue, the requests continue to be processed by the instruction cache. When data from flushed requests are returned, there will not be any valid matches in the queue, and the data will be ignored. Note that it would be possible to change the thread mask after fetching the instruction and only flush the instructions if they follow the wrong execution path. This would however require much more control logic.  

Upon flushing, the warp is marked as stalled in the warp scheduler, the \acrshort{pc} is also set to address after the instruction causing the front-end stall. This is done by sending the \acrshort{pc} of the stalling warp back to the warp scheduler from decode. Using the new icache-stage give greater flexibility of the order in which the warps can be scheduled, as they only stall when required. 

\subsection{Stall Prediction}

The implementation of \acrshort{nss} presented in Section \ref{sec:no_stall_scheduling} has one main weakness: the cost of mispredicting is large. Mispredicting will likely waste cycles, as there is a high probability that the GPU could fetch other non-speculative warps. Thus the cost is not relative to not fetching any warps, but rather relative to scheduling a number of other warps. To combat this issue I propose implementing \textit{stall-prediction}, allowing the warp scheduler to learn if an instruction will cause a frontend stall.

Figure \ref{fig:stall_table} shows the \textit{stall-table} used to learn which instructions are causing a frontend stall. The stall-table is included in the fetch stage and is used to lookup whether the next warp should be blocked from being fetched. \textcircled{\small{1}} The \acrshort{pc} of the fetched warp is used as an index in stall table. It is split into a number of tag and index bits, the number of bits is dependant on the size of the table, see Equation~\ref{eq:table_size}. \textcircled{\small{2}} If the tags are matching and the table entry is valid, the instruction will require the next warp to stall. By stalling the next warp, other warps can be fetched instead of continuing to fetch instructions which will be flushed.

\begin{equation} \label{eq:table_size}
\begin{gathered}
    \#IndexBits = \ceil*{\text{log}_2(TableSize)} \\
    \#TagBits = \#PCBits - \floor*{\text{log}_2(TableSize)} - 2
\end{gathered}
\end{equation}

For the stall-table to learn, \textcircled{\small{3}} the \acrshort{pc} and stall status of the decoded instructions are sent to the stall-table. If the instruction is a stall, the tag and valid bit is set at the corresponding index. Note that this may invalidate a previous entry by overwriting the tag. If the instruction does not cause a stall, nothing is written to the stall table. Thus the stall-table contains only instructions which is known to cause a stall.

The index bits can be any subset of the \acrshort{pc} bits, but I elected to use the \acrfullpl{lsb}, except the last two which are always zero. By using the \acrshortpl{lsb} as index, the stall table will be able to handle consecutive stalling instructions. The stall-table will only be effective when instructions are executed multiple times, i.e loops or \acrshortpl{tb} executing the same instructions. Thus it is more valuable for the stall-table to have high accuracy within the loop, than wide coverage. Preliminary testing showed that having 128 entries gave a high hit rate in the stall-table. Increasing the size further started to give diminishing returns in the and did not improve the hit rate by much. 

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figures/stall_table.png}
    \caption[Illustration of the stall table.]{Illustration of the stall-table, which is used to check if an instruction is known to require stalling}
    \label{fig:stall_table}
\end{figure}

% \subsection{Warp scheduling}

% \textcolor{red}{After implementing no-stall-scheduling, we are able to implement a GTO in the warp scheduler}

\subsection{Back Pressure Reduction}

When implementing \acrshort{nss} and the stall table, the throughput of the frontend is increased. The increase in throughput may cause the instruction buffer to fill up, resulting in back pressure as illustrated in Figure \ref{fig:backpressure}. This occurs when the the decoder decodes an instruction which there is no space for in the instruction buffer. As the decoder is unable to send the instruction to issue, it is blocking until there is space in the ibuffer. This may be problematic because the back pressure could block ready instructions from being decoded. This will impair the throughput, as these warps might be able to issue.

This problem can be resolved by implementing what I will refer to as \acrfull{bpr}. \acrshort{bpr} is quite simple a bitmask sent from the ibuffer to the icache-stage indicating which ibuffer lanes are full. This allows the icache-stage to always select instructions to be decoded which will not cause back pressure.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/backpressure.png}
    \caption[Illustration of back pressure from the ibuffer to the icache-stage.]{Back pressure from the instruction buffer to decode. Ready warps in the icache-stage are blocked from being decoded and sent to the instruction buffer, because the instruction buffer of the decoded warp is full. The instruction buffers of $W_1, W_2$ and $W_3$ are empty, and have to wait for $W_4$ to issue before being filled}
    \label{fig:backpressure}
\end{figure}

% \textcolor{red}{If one of the ibuffers is full, it may cause backpressure into decode and fetch. Even if the icache stage has ready instructions, they cannot be decoded and issued. This may result in a state where only one warp is available in the ibuffer, while decode and the icache stage is stalling because it is waiting for the correct ibuffer slot to be available. If this warp is stalled due to a long latency stall, no other warps can be issued to hide the stall}

% \textcolor{red}{Figure \ref{fig:backpressure} shows the number of cycles per instruction where a warp is blocked in decode because of full ibuffers. ** Describe Notable elements of the graph **}

% \textcolor{red}{To resolve this issue, a signal is sent from the ibuffer to the warp scheduler and (icache stage for selector) indicating for each ibuffer if it is full or not}

% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{figures/backpressure/L2.png}
%     \caption{Backpressure, placeholder}
%     \label{fig:backpressure}
% \end{figure}