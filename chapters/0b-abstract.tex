\chapter*{Abstract}

While software simulation is a common method for performing computer architecture research, it is slow for highly parallel architectures such as \acrshortpl{gpu}. A detailed simulation of a fully sized \acrshort{gpu} can take several days. \acrshortpl{fpga} are reconfigurable integrated circuits, which can be used to accelerate computer architecture simulations. They are thus a middle ground between slow software simulations and expensive hardware prototypes.

\Gls{vortex} is a \Gls{riscv} based \acrshort{gpgpu} capable of being \acrshort{fpga}-accelerated, thus being a good candidate for \acrshort{gpu} architecture research. In my project thesis~\cite{Aurud_Project}, I added support for generating cycles per instruction (CPI) stacks for \Gls{vortex}, which enabled me to identify potential performance bottlenecks in \Gls{vortex}' frontend and schedulers. These issues inhibit \Gls{vortex} from exploiting parallelism and hiding stalls, reducing its throughput.

In this thesis, I implement and evaluate three improvements to the \Gls{vortex} microarchitecture. First, I implement \textit{ready scheduling}, enabling \Gls{vortex} to know which warps are ready before issuing them. Secondly, I improve the throughput of \Gls{vortex}' frontend by allowing it to fetch instructions without stalling. I also implement stall prediction to make \Gls{vortex} learn when stalls are required. Finally, I implement a \acrfull{gto} scheduling algorithm and compare its performance with the existing \acrfull{lrr} scheduler.

In my project thesis, the generation of \acrshort{cpi} stacks was closely connected to the existing issue scheduler. It only sampled the stall cause of the warp selected by the scheduler. In this thesis, I expand upon this method, sampling the stall cause of all warps in the issue stage. This gives a greater overview of why \Gls{vortex} is stalling. Additionally, I broaden \Gls{vortex}' lacking benchmark suite by porting 16 benchmarks from \Gls{rodinia}, a commonly used set of \acrshort{gpu} benchmarks. This involves altering core components of \Gls{vortex}' system for reading performance data and changing the benchmarks' source code to accommodate for some missing OpenCL functionality. 

Implementing \textit{ready scheduling}, removes all missed opportunities for issuing warps. For benchmarks with low-latency stalls, such as \textit{psort}, this change is enough to hide the stalls, reducing \acrshort{cpi} by $20\%$. \textit{Ready scheduling} does however have less impact on benchmarks bounded by long-latency stalls. The frontend improvements are able to increase the frontend bandwidth, reducing the average number of frontend-related stalls by $71\%$. For \textit{sfilter}, all frontend stalls are removed. This is because the improved frontend only stalls to handle control flow, and \textit{sfilter} does not have any control flow instructions. However, the \acrshort{cpi} is not reduced to the same degree. On average, the combined improvement of the frontend and \textit{ready scheduling}, reduces \acrshort{cpi} by $5.4\%$. This is because the latencies are too long to be hidden by the current \Gls{vortex} configuration, which is too small. The bottleneck is thus moved to the backend. The size of the \Gls{vortex} configuration is also the reason why there is no significant performance difference between using an \acrshort{lrr} and \acrshort{gto} scheduler.